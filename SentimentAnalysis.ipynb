{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895125ce-78b6-4844-971f-736059c818c3",
   "metadata": {},
   "source": [
    "# Title: Sentiment Analysis\n",
    "# Author: Touseef Asif\n",
    "# Objective : To build a Python-based Sentiment Analysis model for classifying IMDB reviews as positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2e839-8e49-46b4-9c7a-fddd758f5976",
   "metadata": {},
   "source": [
    "# Task 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cadb5e-89a6-4328-ad5e-874fc714ccbf",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "967ad90f-5746-42b4-9ba1-d19b923d5145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample stopwords: ['mightn', 'our', 'an', 'further', 'theirs', 'isn', \"she's\", 'didn', 'so', \"should've\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Touseef\n",
      "[nltk_data]     Asif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Display stopwords for reference\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(\"Sample stopwords:\", list(stop_words)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd822301-e982-45ba-9017-693305ef8b98",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2784705-9c75-4c39-8bdd-c93d370d3569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Touseef\n",
      "[nltk_data]     Asif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Touseef\n",
      "[nltk_data]     Asif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Download NLTK Resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e308ae3-0a0b-4504-8710-1a9db13ef9f8",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67a80711-a4c2-4fd4-9c47-98afab127619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "\n",
      "Number of null values in each column:\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (update the file path)\n",
    "file_path = \"IMDB Dataset.csv\"  # Update with your dataset path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for null values and basic info\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Check for null values\n",
    "print(\"\\nNumber of null values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ccf1f-f1e1-4e48-bc51-4429995cfe5c",
   "metadata": {},
   "source": [
    "# Preprocessing the Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73350ba6-61c6-4296-8965-be5c133d794e",
   "metadata": {},
   "source": [
    "**Text preprocessing involves cleaning and preparing the text for analysis.**\n",
    "\n",
    "**1**. Convert Text to Lowercase\n",
    "**2**. Remove Stopwords and Special Characters\n",
    "**3**. Tokenization (splitting text into words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b1fa5a3-ad9c-4193-b6f5-bd0245ed3766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed text sample:\n",
      "0    one reviewers mentioned watching oz episode yo...\n",
      "1    wonderful little production br br filming tech...\n",
      "2    thought wonderful way spend time hot summer we...\n",
      "3    basically theres family little boy jake thinks...\n",
      "4    petter matteis love time money visually stunni...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Convert text to lowercase\n",
    "df['review'] = df['review'].str.lower()\n",
    "\n",
    "# Step 2: Remove special characters\n",
    "df['review'] = df['review'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "\n",
    "# Step 3: Remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df['review'] = df['review'].apply(remove_stopwords)\n",
    "\n",
    "# Display preprocessed data\n",
    "print(\"Preprocessed text sample:\")\n",
    "print(df['review'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153e0643-6093-4c5d-ba60-de51fd3c5641",
   "metadata": {},
   "source": [
    "# Feature Engineering (Convert Text to Numerical Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af159c4-a974-4229-bfcc-b06ea053aa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features: ['aaron' 'abandoned' 'abc' 'abilities' 'ability' 'able' 'aboutbr'\n",
      " 'absence' 'absent' 'absolute']\n",
      "\n",
      "Shape of feature matrix: (50000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Convert text data to numerical format using CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000)  # Use the top 5000 features\n",
    "X = vectorizer.fit_transform(df['review']).toarray()\n",
    "\n",
    "# Display feature names and sample data\n",
    "print(\"Top 10 features:\", vectorizer.get_feature_names_out()[:10])\n",
    "print(\"\\nShape of feature matrix:\", X.shape)\n",
    "\n",
    "# Target variable (positive or negative)\n",
    "y = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)  # 1: Positive, 0: Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8435c3b8-8f3d-422f-b0ff-bfa47f766ed9",
   "metadata": {},
   "source": [
    "# Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ff6ba1-9242-4da5-9f4b-5be1e0d52a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (40000, 5000)\n",
      "Testing data shape: (10000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display split information\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c927af-b132-4d85-adbd-af9b965c8024",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aff37f60-f864-42ca-9241-5758beeb7571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Touseef Asif\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Display model training status\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52085154-7af0-4af9-bdf0-c65bf0c2d7ac",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df341895-b66a-4aef-a6b1-9a2b6620d3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      4961\n",
      "           1       0.87      0.88      0.88      5039\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Optional: Display a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd792a-d093-4990-98e3-7ba87a6bea7b",
   "metadata": {},
   "source": [
    "# Predict Sentiment for a New Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "146725ef-1c3f-4b6a-ab02-b5066eeb2605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Review Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess and predict sentiment for new reviews\n",
    "def predict_sentiment(review):\n",
    "    # Preprocess the review\n",
    "    review = review.lower()\n",
    "    review = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "    review = remove_stopwords(review)\n",
    "    review_vectorized = vectorizer.transform([review]).toarray()\n",
    "    \n",
    "    # Predict sentiment\n",
    "    prediction = model.predict(review_vectorized)\n",
    "    return \"Positive\" if prediction[0] == 1 else \"Negative\"\n",
    "\n",
    "# Example: Test the function\n",
    "new_review = \"This movie was absolutely amazing! I loved it.\"\n",
    "print(\"New Review Sentiment:\", predict_sentiment(new_review))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
